{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f115b718-8a58-47a7-9b69-bcd95cfb440d",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07364a01-5a10-49f0-9a3a-d8035e06893b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.optim import SGD, Adam, AdamW\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.datasets import DatasetFolder, ImageFolder\n",
    "from tqdm import tqdm\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, \\\n",
    "accuracy_score\n",
    "from avalanche.models import SlimResNet18, MTSlimResNet18, SimpleCNN\n",
    "from avalanche.models import as_multitask, IncrementalClassifier\n",
    "from avalanche.models.utils import avalanche_model_adaptation\n",
    "from avalanche.training import Naive, LwF, GenerativeReplay, ICaRLLossPlugin, ICaRL, EWC, AR1, LFL, AGEM\n",
    "from avalanche.logging import (\n",
    "    InteractiveLogger,\n",
    "    TextLogger,\n",
    "    CSVLogger,\n",
    ")\n",
    "from avalanche.training.plugins import EvaluationPlugin, ReplayPlugin, LwFPlugin, EarlyStoppingPlugin, AGEMPlugin\n",
    "from avalanche.training.plugins.lr_scheduling import LRSchedulerPlugin\n",
    "from avalanche.benchmarks import nc_benchmark, ni_benchmark\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from avalanche.benchmarks.scenarios.dataset_scenario import benchmark_from_datasets\n",
    "from avalanche.benchmarks.scenarios.supervised import class_incremental_benchmark\n",
    "from avalanche.evaluation.metrics import forgetting_metrics, accuracy_metrics,loss_metrics, \\\n",
    "timing_metrics, cpu_usage_metrics, StreamConfusionMatrix, disk_usage_metrics, gpu_usage_metrics, \\\n",
    "confusion_matrix_metrics, bwt_metrics, forward_transfer_metrics, ram_usage_metrics, images_samples_metrics\n",
    "from avalanche.evaluation.metrics import Accuracy, BWT, Forgetting, ForwardTransfer\n",
    "import multiprocessing as mp\n",
    "import my_utils\n",
    "import my_architectures\n",
    "import my_dataloaders\n",
    "# import my_gwpy_and_fractals\n",
    "import my_transformations\n",
    "IMG_SIZE = (224,224)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a477c1d8-e42d-40a2-8fb2-88bd288b1d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# calculating the amount of workers usable\n",
    "number_of_workers = mp.cpu_count()\n",
    "number_of_workers = int(number_of_workers/2)\n",
    "print(number_of_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff14e29-1192-4523-b1a8-1e9fbf34d16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the correct directories\n",
    "#train_dir = 'D:\\\\Users\\\\Brian\\\\TrainingSet_CL_1\\\\TrainingSet_CL_1'\n",
    "train_dir = 'C:\\\\Users\\\\Brian.Baert\\\\TrainingSet_CL_1'\n",
    "#train_dir_2 = 'D:\\\\Users\\Brian\\\\TrainingSet_CL_2\\\\TrainingSet_CL_2'\n",
    "train_dir_2 = 'C:\\\\Users\\\\Brian.Baert\\\\TrainingSet_CL_2'\n",
    "#val_dir = 'D:\\\\Users\\\\Brian\\\\TestSet_CL\\\\TestSet_CL'\n",
    "val_dir = 'C:\\\\Users\\\\Brian.Baert\\\\ValidationSet_CL'\n",
    "#test_dir = 'D:\\\\Users\\\\Brian\\\\TestSet_CL\\\\TestSet_CL'\n",
    "test_dir = 'C:\\\\Users\\\\Brian.Baert\\\\TestSet_CL'\n",
    "\n",
    "# Read in class labels\n",
    "class_file = open(\"classes.txt\", \"r\")\n",
    "classes = class_file.read()\n",
    "classes = classes.split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f9d74b4-8383-4688-94fb-7a7b074e9527",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = my_architectures.MultiViewColorNet_resnet18(num_classes=10)\n",
    "model.to(device)\n",
    "# log to text file\n",
    "text_logger = TextLogger(open(\"naive_log.txt\", \"a\"))\n",
    "# print to stdout\n",
    "interactive_logger = InteractiveLogger()\n",
    "csv_logger = CSVLogger()\n",
    "classes = my_utils.get_classes_from_dir(train_dir_2)\n",
    "class_to_indx = my_utils.classes_to_indices(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13166c6a-312b-4215-996f-e5a7c20628e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Blip', 'Blip_Low_Frequency', 'Extremely_Loud', 'Fast_Scattering', 'Koi_Fish', 'Low_Frequency_Burst', 'Low_Frequency_Lines', 'Scattered_Light', 'Tomte', 'Whistle']\n"
     ]
    }
   ],
   "source": [
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "170d745a-07f7-47d8-872c-12dc6d88b872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Skipping class 'Blip': Not all versions found.\n",
      "Warning: Skipping class 'Blip_Low_Frequency': Not all versions found.\n",
      "Warning: Skipping class 'Extremely_Loud': Not all versions found.\n",
      "Warning: Skipping class 'Fast_Scattering': Not all versions found.\n",
      "Warning: Skipping class 'Koi_Fish': Not all versions found.\n",
      "Warning: Skipping class 'Low_Frequency_Burst': Not all versions found.\n",
      "Warning: Skipping class 'Low_Frequency_Lines': Not all versions found.\n",
      "Warning: Skipping class 'Scattered_Light': Not all versions found.\n",
      "Warning: Skipping class 'Tomte': Not all versions found.\n",
      "Warning: Skipping class 'Whistle': Not all versions found.\n",
      "Warning: Skipping class 'Blip': Not all versions found.\n",
      "Warning: Skipping class 'Blip_Low_Frequency': Not all versions found.\n",
      "Warning: Skipping class 'Extremely_Loud': Not all versions found.\n",
      "Warning: Skipping class 'Fast_Scattering': Not all versions found.\n",
      "Warning: Skipping class 'Koi_Fish': Not all versions found.\n",
      "Warning: Skipping class 'Low_Frequency_Burst': Not all versions found.\n",
      "Warning: Skipping class 'Low_Frequency_Lines': Not all versions found.\n",
      "Warning: Skipping class 'Scattered_Light': Not all versions found.\n",
      "Warning: Skipping class 'Tomte': Not all versions found.\n",
      "Warning: Skipping class 'Whistle': Not all versions found.\n",
      "Warning: Skipping class 'Blip': Not all versions found.\n",
      "Warning: Skipping class 'Blip_Low_Frequency': Not all versions found.\n",
      "Warning: Skipping class 'Extremely_Loud': Not all versions found.\n",
      "Warning: Skipping class 'Fast_Scattering': Not all versions found.\n",
      "Warning: Skipping class 'Koi_Fish': Not all versions found.\n",
      "Warning: Skipping class 'Low_Frequency_Burst': Not all versions found.\n",
      "Warning: Skipping class 'Low_Frequency_Lines': Not all versions found.\n",
      "Warning: Skipping class 'Scattered_Light': Not all versions found.\n",
      "Warning: Skipping class 'Tomte': Not all versions found.\n",
      "Warning: Skipping class 'Whistle': Not all versions found.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m test_set \u001b[38;5;241m=\u001b[39m my_dataloaders\u001b[38;5;241m.\u001b[39mMultiViewGravitySpyDataset(root\u001b[38;5;241m=\u001b[39mtest_dir, classes\u001b[38;5;241m=\u001b[39mclasses, transform\u001b[38;5;241m=\u001b[39mmy_transformations\u001b[38;5;241m.\u001b[39mtransformAV_224)\n\u001b[0;32m      5\u001b[0m train_set_av \u001b[38;5;241m=\u001b[39m AvalancheDataset(train_set)\n\u001b[1;32m----> 6\u001b[0m train_loader_av \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber_of_workers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m val_set_av \u001b[38;5;241m=\u001b[39m AvalancheDataset(val_set)\n\u001b[0;32m      9\u001b[0m val_loader_av \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(val_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mnumber_of_workers)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\MscThesis\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:344\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[1;32m--> 344\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    346\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\MscThesis\\lib\\site-packages\\torch\\utils\\data\\sampler.py:107\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[1;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement))\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue, but got num_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples))\n",
      "\u001b[1;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "train_set = my_dataloaders.MultiViewGravitySpyDataset(root=train_dir, classes=classes, transform=my_transformations.transformAV_224_Crop)\n",
    "val_set = my_dataloaders.MultiViewGravitySpyDataset(root=val_dir, classes=classes, transform=my_transformations.transformAV_224)\n",
    "test_set = my_dataloaders.MultiViewGravitySpyDataset(root=test_dir, classes=classes, transform=my_transformations.transformAV_224)\n",
    "\n",
    "train_set_av = AvalancheDataset(train_set)\n",
    "train_loader_av = torch.utils.data.DataLoader(train_set, batch_size=32, shuffle=True, num_workers=number_of_workers)\n",
    "\n",
    "val_set_av = AvalancheDataset(val_set)\n",
    "val_loader_av = torch.utils.data.DataLoader(val_set, batch_size=32, shuffle=True, num_workers=number_of_workers)\n",
    "\n",
    "test_set_av = AvalancheDataset(test_set)\n",
    "test_loader_av = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=True)\n",
    "\n",
    "train_set_av.targets = train_set.labels\n",
    "test_set_av.targets = test_set.labels\n",
    "val_set_av.targets = val_set.labels\n",
    "\n",
    "train_set_av.uniques = list(set(train_set.labels))\n",
    "test_set_av.uniques = list(set(test_set.labels))\n",
    "val_set_av.uniques = list(set(val_set.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9870125-a945-414c-bf45-99ee0e5e2f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
